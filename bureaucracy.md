---
tags:
  - type/article
publication:
  - Midnight Musings
source: https://dhruvmethi.substack.com/p/bureaucracy
created: 2025-04-03
---
# bureaucracy

> [!abstract] Summary
## Highlights
---
> As an organization, you have two levers to improve: increase meaningful output while using the same amount of resources, or maintain the same meaningful output while decreasing the amount of resources spent.

> Within the mess of systems, committees, and processes, the production of meaningful output becomes impossible, and sustaining this complexity requires an immense amount of resources.

> The worst part is that they’re extremely static and difficult to change. This is because:
> 1. Inertia - the size and complexity of bureaucracy create tremendous inertia behind the status quo. It takes an overwhelming amount of energy to both map it and change it in a positive way. Few people are willing to take the plunge, and fewer power brokers within the bureaucracy will support any change because it would threaten their position.
> 2. Illusory work - the effort required to survive within the bureaucracy leaves little room and energy to change it.

> The CIA provides evidence that bureaucracy can be built through distinct actions. Here are a few guidelines from their handbook on how to disrupt activist organizations ... In the abstract, a lot of these actions seem benign!
> - “Haggle over precise wordings” - it’s hard to object to people showing attention to detail because it seems as if they’re extremely invested in the outcome.
> - “Refer all matters to committees” - how can you object to delegating decisions to subject matter experts?
> - “Be worried about the propriety of any decision” - it seems extremely important to ensure that you’re acting within scope and not exposing your organization to risk.

> 1. **Poorly designed incentive systems** - many incentive systems punish mistakes but fail to reward successes, causing organizations to be overly risk-averse. For example, the FDA is punished for permitting harmful drugs to be sold on the market, but they’re not punished for stalling research that could save lives and they’re not rewarded for supporting transformative innovation.
> 2. **Loose coupling of systems with desired outcomes** - there’s often minimal connection between systems and processes put in place and desired organizational outcomes, even if the systems seem benign or helpful. For example, in engineering teams, it may seem like a good and safe idea to get consensus from leadership on every important architectural decision, but the desire for consensus can conflict with the organizational goal of releasing features at a high velocity to remain competitive.

> The IRB story illustrates a common pattern:
> - A very bad thing is happening.
> - A review and approval process is created to prevent these bad things. This is OK at first, and fewer bad things happen.
> - Then, another very bad thing happens, despite the approval process.
> - Everyone decides that the review was not strict enough. They make the review process stricter.
> - Repeat this enough times (maybe only once, in the case of IRBs!) and you get regulatory overreach.

> It’s a case of poorly designed incentives. The IRB receives no reward for enabling or supporting research, and it receives no recognition when the research directly saves or improves many lives. Instead, it is given all the blame for any harm that comes to patients.

> Instead, I think a better approach is to have a different mentality around mistakes. I really like the concept of [statistical process control](https://www.advantive.com/solutions/spc-software/what-is-spc/) (SPC). The goal of SPC is to improve quality by reducing variance. It understands certain outcomes as simple variance, and the goal of the few processes in place is to reduce variance while improving key organizational metrics.

> This is an example of a system that’s not aligned with a desired outcome. If you run a meeting in which there’s no clear value returned from it, you’ve invested organizational resources while not increasing meaningful output.

> - **Systems to build consensus** - it takes a lot of effort to get people aligned. Even though this is something that seems positive, it is very rarely worth the effort. Consensus can be affected by group decision-making biases leading to worse decisions, and it can prevent organizations from making bold decisions that can have outsized benefits. Additionally, consensus is fragile; people’s minds change faster than you might imagine.
> - **Status updates** - standup meetings are a meme these days. Again, a system born out of good intentions (we should all be on the same page and work collaboratively!), but often devolves into micromanagement and frustration, never really delivering value for the people in the meetings. Another system that is rarely aligned with desired outcomes.

> Sometimes, the answer to fixing a poorly designed system is to just tweak the existing system. In the example of meetings, perhaps the meeting is necessary to get everyone on the same page, but the lack of a prepared agenda and post-meeting recap is preventing that meeting from being useful.

> I think there are 4 components to effectively designed systems:
> 1. **Clear problem statement** - each system or process must be coupled with a clear problem that it is meant to solve. For example, a problem statement could be “Our product team and marketing team are unaware of what they’re each working on, causing our marketing team to have to frequently rework their assets and communications.”
> 2. **Clear target metric to improve** - using the same example above, a target metric could be the number of times the marketing team has to redo their work.
> 3. Intentional system design** - an example here could be “To make the two teams aligned, we’re going to add a monthly meeting for each team to share their roadmap. The goal of this meeting is to reduce the work done by the marketing team”
> 4. Commitment to study the metric** - this is crucial! Many people just forget about why systems are installed or what they’re meant to fix. You have to intentionally study the metric and make observations to see if the system is actually doing what it’s meant to. This will let you know if it’s worth keeping or not. An example could be to commit to revisit the metric in 3 months and assess if there has been a measurable improvement.

> The key here is that these systems have to be **malleable**. Just because it worked for a short period doesn’t mean it will work forever! Perhaps the problem no longer exists, or perhaps the organizational goals have changed.

> None of this is easy. To do this right, you have to deeply understand your organization and its purpose. You have to be deliberate with your actions and intentions, frequently revisiting things and tweaking them as the surrounding context changes.

> To make it harder, it is not sufficient to do something that is a “best practice”. You must marry the **right action** with the **right context** because if it’s not coupled well, you’re on the way to creating a bureaucratic maze.
## Citation
---
```
D. Methi, "bureaucracy", Midnight Musings.
https://dhruvmethi.substack.com/p/bureaucracy
```
---
##### Completion Checklist
###### II. From Dark to Dawn
- [ ] Read the article again, this time copy pasting interesting sections into the note under `Highlights`.
- [ ] **Bold** the portions of the `Highlights` you find most interesting.
- [ ] ==Highlight== the best parts of the bolded sections.
- [ ] Update status tag to `status/dawn`.
###### III. From Dawn to Day
- [ ] Write the article `Summary`.
- [ ] Fill in the context tags for the metadata.
- [ ] Update status tag to `status/day`.
- [ ] Remove this checklist.
