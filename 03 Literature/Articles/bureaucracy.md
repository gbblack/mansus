---
tags:
  - type/article
  - leadership
  - status/day
publication:
  - Midnight Musings
source: https://dhruvmethi.substack.com/p/bureaucracy
created: 2025-04-03
---
# bureaucracy

> [!abstract] Summary
> An article on the creation of bureaucracies in organisations, their crippling affects on the organizations abilities and actions you can take to prevent/mitigate this in your own organizational structures.
## Highlights
---
As an organization, **you have two levers to improve: ==increase meaningful output== while using the ==same amount of resources==, ==or maintain the same meaningful output ==while ==decreasing== the amount of ==resources== spent.**

Within the mess of systems, committees, and processes, the production of meaningful output becomes impossible, and **sustaining this complexity requires an immense amount of resources.**

The worst part is that they’re extremely **static and difficult to change**. This is because:
1. **==Inertia==** - the **==size and complexity== of bureaucracy create tremendous inertia** behind the status quo. It takes an overwhelming amount of energy to both map it and change it in a positive way.
2. **Illusory work** - the **==effort== required ==to survive== within the bureaucracy** leaves little room and energy to change it.

The CIA provides evidence that bureaucracy can be built through distinct actions. Here are a few guidelines from their handbook on how to disrupt activist organizations ... **In the ==abstract==, a lot of these ==actions seem benign==!**
- **==“Haggle over precise wordings”==** - it’s hard to object to people showing attention to detail because it seems as if they’re extremely invested in the outcome.
- **==“Refer all matters to committees”==** - how can you object to delegating decisions to subject matter experts?
- **==“Be worried about the propriety of any decision”==** - it seems extremely important to ensure that you’re acting within scope and not exposing your organization to risk.

1. **Poorly designed incentive systems** - many **==incentive systems punish mistakes but fail to reward successes==, causing organizations to be overly risk-averse.** For example, the FDA is punished for permitting harmful drugs to be sold on the market, but they’re not punished for stalling research that could save lives.
2. **Loose coupling of systems with desired outcomes** - there’s **often ==minimal connection between systems== and processes put in place and ==desired== organizational ==outcomes==**, even if the systems seem benign or helpful.

The IRB story illustrates a common pattern:
- A very bad thing is happening.
- A review and approval process is created to prevent these bad things. This is OK at first, and fewer bad things happen.
- Then, another very bad thing happens, despite the approval process.
- Everyone decides that the review was not strict enough. They make the review process stricter.
- Repeat this enough times (maybe only once, in the case of IRBs!) and you get regulatory overreach.

It’s a case of **==poorly designed incentives.==** The IRB receives no reward for enabling or supporting research, and it receives no recognition when the research directly saves or improves many lives.

Instead, I think a **==better approach== is to have a ==different mentality around mistakes==**. I really like the concept of **statistical process control (SPC). The goal of SPC is to ==improve quality by reducing variance.**== It understands certain outcomes as simple variance, and the goal of the few processes in place is to reduce variance while improving key organizational metrics.

This is an example of a system that’s not aligned with a desired outcome. If you run a meeting in which there’s no clear value returned from it, you’ve invested organizational resources while not increasing meaningful output.

- **Systems to build consensus** - it takes a lot of effort to get people aligned. Even though this is something that seems positive, it is very rarely worth the effort. **==Consensus== can be affected by group decision-making ==biases leading to worse decisions==**, and it can prevent organizations from making bold decisions that can have outsized benefits.

I think there are 4 components to effectively designed systems:
1. **Clear problem statement** - **each ==system or process must be coupled with a clear problem== that it is meant to solve.** For example, a problem statement could be “Our product team and marketing team are unaware of what they’re each working on, causing our marketing team to have to frequently rework their assets and communications.”
2. ==**Clear target metric to improve**== - using the same example above, a target metric could be the number of times the marketing team has to redo their work.
3. ==**Intentional system design**== - an example here could be “To make the two teams aligned, we’re going to add a monthly meeting for each team to share their roadmap. The goal of this meeting is to reduce the work done by the marketing team”
4. **Commitment to study the metric** - Many people just forget about why systems are installed or what they’re meant to fix. You have to **==intentionally study the metric== and make observations to see if the system is actually doing what it’s meant to.**

The key here is that these **systems have to be ==malleable**==. Just because it worked for a short period doesn’t mean it will work forever! Perhaps the problem no longer exists, or perhaps the organizational goals have changed.

None of this is easy. **To do this right, ==you have to deeply understand your organization and its purpose.== You have to be ==deliberate== with your actions and intentions, frequently revisiting things and tweaking them ==as the surrounding context changes.==**

To make it harder, **it is ==not sufficient== to do something that is a ==“best practice”.==** You must **marry the ==right action== with the ==right context==** because if it’s not coupled well, you’re on the way to creating a bureaucratic maze.
## Citation
---
```
"bureaucracy", Midnight Musings.
https://dhruvmethi.substack.com/p/bureaucracy
```
