---
tags:
  - type/article
  - status/day
  - AI
publication:
  - Ali Alkhatib
source: https://ali-alkhatib.com/blog/defining-ai
created: 2025-10-14
---
# Defining AI

> [!abstract] Summary
> An article admonishing the current popular definition of AI as relying too heavily on arbitrary technological boundaries. It asks instead to redefine AI as the political construct it is, with boundaries set by real world affects that can easily be recognised and quantified.
## Highlights
---
One might inspect handguns and stun guns, come to the conclusion that these are two totally different technologies because they don’t operate on the same technical principles at all, and embarrassingly overlook that they’re obviously both tools police use to maim and kill people. **You don’t need to deconstruct a handgun and a stun gun to ==understand== their adjacent, often overlapping, ==roles in _policing_.== Fixating on the firing mechanisms ==can apparently desensitize someone to the political neighborhood these technologies share**==, and make a person a very unreliable ally in an ongoing collective struggle to abolishing policing.

**I think we should shed the idea that ==AI is== a technological artifact with political features and recognize it as ==a political artifact through and through.**== **AI is an ==ideological project to shift authority and autonomy away from individuals,== towards centralized structures of power.** Projects that claim to “democratize” ==**AI== routinely ==conflate “democratization” with “commodification”.**== Even open-source AI projects often borrow from libertarian ideologies to help manufacture little fiefdoms.

This way of thinking about AI (as a political project that happens to be implemented technologically in myriad ways that are inconsequential to identifying the overarching project as “AI”) brings the discipline - reaching at least as far back as the 1950s and 60s, drenched in blood from military funding - into focus as part of the same continuous tradition.

**Defining AI along ==political and ideological language allows us to think about things _we experience_ and recognize productively as AI**==, without needing the self-serving supervision of computer scientists to allow or direct our collective work. **We can recognize, based on our own knowledge and experience as people who deal with these systems, ==what’s part of this overarching project of disempowerment by the way that it renders autonomy farther away from us, by the way that it alienates our authority on the subjects of our own expertise.==**

**This framework sensitizes us to “small” systems that cause tremendous harm because of the settings in which they’re placed and the authority people place upon them;** and it inoculates us against fixations on things like regulating systems just because they happened to use `10^26` floating point calculations in training - an arbitrary threshold, denoting nothing in particular, beneath which actors could (and do) cause monumental harms already, today.
## Citation
---
```
"Defining AI." Ali Alkhatib. https://ali-alkhatib.com/
```