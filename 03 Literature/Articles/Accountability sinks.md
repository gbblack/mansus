---
tags:
  - type/article
  - status/dawn
  - communication
publication:
  - A working library
source: https://aworkinglibrary.com/writing/accountability-sinks
created: 2025-02-24
---
# Accountability sinks

> [!abstract] Summary
> An exploration on "accountability sinks" which are structures in organisations that remove accountability, and therefore consequences, from decision makers by breaking the connection between the decision and is consequences. Usually by breaking communication between two parties.
## Highlights
---
> that organizations form **==“accountability sinks,”== structures that absorb or ==obscure the consequences of a decision== such that ==no one== can be ==held directly accountable for it==.**

> There’s no one to call to complain, **==no way to communicate back== to that distant leader** that they’ve scotched your plans.

> For an accountability sink to function, ==**it has to break a link==; it has to prevent the feedback** of the person affected by the decision from affecting the operation of the system.

> Once you start looking for accountability sinks, you see them all over the place. When your health insurance declines a procedure; when the airline cancels your flight

> Everywhere, broken links between the people who face the consequences of the decision and the people making the decisions.

> hat’s **assuming, of course, that a ==person _did_ make a decision== at all.** Another mechanism of accountability sinks is the way in **which ==decisions themselves cascade and lose any sense of their origins.**==

> which Fox News repeatedly spread false stories about the election. No one at Fox seems to have explicitly made a decision to lie about voting machines; rather, there was an implicit understanding that they had to do whatever it took to keep their audience numbers up.

> **But who can be ==accountable to a decision that wasn’t actually made?**==

> The fundamental law of accountability: **the extent to which you are able to ==change a decision**== is precisely **the extent to which you can be ==accountable for it**==, and vice versa.

> where an account is _something that you tell._ How did something happen, what were the conditions that led to it happening, … All of those questions and more **are necessary for ==understanding how a decision happened==**

> that **to be accountable for something you must have ==the power to change it _and_ understand**== what you are trying to accomplish when you do.

> The comparisons to AI are obvious, inasmuch as **delegating ==decisions to an algorithm== is a convenient way to ==construct a sink.==**

> The accountability-washing that an AI provides isn’t a new service so much as an escalated and expanded one.

> Any effort that’s tried and failed to hold a corporation to account isn’t likely **to have more ==success against an algorithm. We need a new bag of tricks**==
## Citation
---
```
"Accountability sinks",A working library.
Available: https://aworkinglibrary.com/writing/accountability-sinks
```
